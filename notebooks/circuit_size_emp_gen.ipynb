{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 threads available on this machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np\n",
    "from src.input.write_files import write_int_matrix_file\n",
    "from src.input.read_files import find_files, numbers_from_file_name, normal_sec_size_int_from_file_name, number_from_text\n",
    "from datetime import datetime\n",
    "from src.algorithm.vanilla.circuit_synthesis import synthesise_circuit\n",
    "from src.algorithm.vanilla.execution import load_matrix_and_benchmark\n",
    "import csv\n",
    "\n",
    "print(f'There are {cpu_count()} threads available on this machine.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "sample_size = 1\n",
    "lower_size = 120\n",
    "upper_size = 200\n",
    "step_size = 100\n",
    "\n",
    "sizes = np.arange(lower_size, upper_size + step_size, step_size)\n",
    "samples = np.arange(1, sample_size + 1, 1)\n",
    "\n",
    "input_gen_processors = 10\n",
    "\n",
    "input_dir = r'resources\\section_size_benchmark\\input_matrices'\n",
    "input_file_prefix = 'SingMat'\n",
    "\n",
    "benchmark_processors = 10\n",
    "\n",
    "output_dir = r'resources\\section_size_benchmark'\n",
    "output_file_prefix = 'SectionSizeBenchmark'\n",
    "\n",
    "output_file_fieldnames = ['size', 'run', 'sec_size', 'num_gates', 'process_time', 'initial_rss', 'final_rss']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1440000, '..\\\\resources\\\\section_size_benchmark\\\\input_matrices\\\\SingMat_1200_1.txt')\n",
      "(1300, 1690000, '..\\\\resources\\\\section_size_benchmark\\\\input_matrices\\\\SingMat_1300_1.txt')\n",
      "(1400, 1960000, '..\\\\resources\\\\section_size_benchmark\\\\input_matrices\\\\SingMat_1400_1.txt')\n",
      "(1500, 2250000, '..\\\\resources\\\\section_size_benchmark\\\\input_matrices\\\\SingMat_1500_1.txt')\n",
      "(1600, 2560000, '..\\\\resources\\\\section_size_benchmark\\\\input_matrices\\\\SingMat_1600_1.txt')\n",
      "(1700, 2890000, '..\\\\resources\\\\section_size_benchmark\\\\input_matrices\\\\SingMat_1700_1.txt')\n",
      "(1800, 3240000, '..\\\\resources\\\\section_size_benchmark\\\\input_matrices\\\\SingMat_1800_1.txt')\n",
      "(1900, 3610000, '..\\\\resources\\\\section_size_benchmark\\\\input_matrices\\\\SingMat_1900_1.txt')\n",
      "(2000, 4000000, '..\\\\resources\\\\section_size_benchmark\\\\input_matrices\\\\SingMat_2000_1.txt')\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None, None]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_gen_argument_tuples = ([(size, size * size, rf'..\\{input_dir}\\{input_file_prefix}_{size}_{sample}.txt') for size in sizes for sample in samples])\n",
    "\n",
    "[print(argument_tuple) for argument_tuple in input_gen_argument_tuples[:min(10, len(input_gen_argument_tuples))]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 14760 matrices in size range from 5 to 250 ...\n",
      "Saved matrices to resources\\section_size_benchmark\\input_matrices ...\n"
     ]
    }
   ],
   "source": [
    "print(f'Generating {len(input_gen_argument_tuples)} matrices in size range from {lower_size} to {upper_size} ...')\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    with Pool(processes = input_gen_processors) as pool:\n",
    "        pool.starmap(write_int_matrix_file, input_gen_argument_tuples)\n",
    "\n",
    "print(f'Saved matrices to {input_dir} ...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingMat_1200_1.txt\n",
      "SingMat_1300_1.txt\n",
      "SingMat_1400_1.txt\n",
      "SingMat_1500_1.txt\n",
      "SingMat_1600_1.txt\n",
      "SingMat_1700_1.txt\n",
      "SingMat_1800_1.txt\n",
      "SingMat_1900_1.txt\n",
      "SingMat_2000_1.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None, None]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_regex = rf'({input_file_prefix}).*\\.txt'\n",
    "size_regex = r'_\\d+_'\n",
    "sample_regex = r'_\\d+\\.'\n",
    "\n",
    "input_file_names = find_files(rf'..\\{input_dir}', file_regex)\n",
    "input_file_names.sort(key = lambda input_file_name: numbers_from_file_name(input_file_name, size_regex, sample_regex))\n",
    "\n",
    "[print(input_file_name) for input_file_name in input_file_names[:min(10, len(input_file_names))]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   size  sample                path\n0  1200       1  SingMat_1200_1.txt\n1  1300       1  SingMat_1300_1.txt\n2  1400       1  SingMat_1400_1.txt\n3  1500       1  SingMat_1500_1.txt\n4  1600       1  SingMat_1600_1.txt",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>size</th>\n      <th>sample</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1200</td>\n      <td>1</td>\n      <td>SingMat_1200_1.txt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1300</td>\n      <td>1</td>\n      <td>SingMat_1300_1.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1400</td>\n      <td>1</td>\n      <td>SingMat_1400_1.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1500</td>\n      <td>1</td>\n      <td>SingMat_1500_1.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1600</td>\n      <td>1</td>\n      <td>SingMat_1600_1.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_arguments = [(number_from_text(input_file_name, size_regex),\n",
    "                        number_from_text(input_file_name, sample_regex),\n",
    "                        input_file_name)\n",
    "                       for input_file_name in input_file_names]\n",
    "file_name_arguments_df = pd.DataFrame(file_name_arguments, columns=['size', 'sample', 'path'])\n",
    "file_name_arguments_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 5, 1, 'SingMat_1200_1.txt')\n",
      "(1300, 5, 1, 'SingMat_1300_1.txt')\n",
      "(1400, 5, 1, 'SingMat_1400_1.txt')\n",
      "(1500, 5, 1, 'SingMat_1500_1.txt')\n",
      "(1600, 5, 1, 'SingMat_1600_1.txt')\n",
      "(1700, 5, 1, 'SingMat_1700_1.txt')\n",
      "(1800, 5, 1, 'SingMat_1800_1.txt')\n",
      "(1900, 5, 1, 'SingMat_1900_1.txt')\n",
      "(2000, 5, 1, 'SingMat_2000_1.txt')\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None, None]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_sizes_hard = [5]\n",
    "\n",
    "benchmark_tuples_list = [(size, sec_size, sample, path) for size, sample, path in file_name_arguments_df.values.tolist() for sec_size in section_sizes_hard]\n",
    "\n",
    "[print(benchmark_tuple) for benchmark_tuple in benchmark_tuples_list[:min(10, len(benchmark_tuples_list))]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "benchmark_argument_tuples = [(synthesise_circuit,\n",
    "                              size,\n",
    "                              sec_size,\n",
    "                              sample,\n",
    "                              rf'..\\{input_dir}\\{input_file_name}')\n",
    "                             for (size, sec_size, sample, input_file_name) in benchmark_tuples_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking runtime performance in size range from 1200 to 2000 in 10 threads ...\n",
      "Saving results to resources\\section_size_benchmark ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "output_file_timestamp = datetime.now().strftime('%d%m%y_%H%M')\n",
    "\n",
    "print(f'Benchmarking runtime performance in size range from {lower_size} to {upper_size} in {benchmark_processors} threads ...')\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    with Pool(processes = benchmark_processors) as pool:\n",
    "        result_tuples = pool.starmap(load_matrix_and_benchmark, benchmark_argument_tuples)\n",
    "\n",
    "print(f'Saving results to {output_dir} ...')\n",
    "\n",
    "with open(rf'..\\{output_dir}\\{output_file_prefix}_{output_file_timestamp}.csv', mode='w', newline='') as output_file:\n",
    "    writer = csv.DictWriter(output_file, fieldnames=output_file_fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for (size, run, sec_size, num_gates, process_time, initial_rss, final_rss) in result_tuples:\n",
    "\n",
    "        writer.writerow({'size': size, 'run': run, 'sec_size': sec_size, 'num_gates': num_gates, 'process_time': process_time, 'initial_rss': initial_rss, 'final_rss': final_rss})\n",
    "\n",
    "print('Done.')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}