{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# COMPARE SECTION SIZES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IMPORTS\n",
    "\n",
    "Perform imports and check environment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 threads available on this machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np\n",
    "from src.input.write_files import write_int_matrix_file\n",
    "from src.input.read_files import find_files, numbers_from_file_name, normal_sec_size_int_from_file_name, number_from_text\n",
    "from datetime import datetime\n",
    "from src.algorithm.vanilla.circuit_synthesis import synthesise_circuit\n",
    "from src.algorithm.vanilla.execution import load_matrix_and_benchmark\n",
    "import csv\n",
    "\n",
    "print(f'There are {cpu_count()} threads available on this machine.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PARAMETERS\n",
    "\n",
    "Define benchmark parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "sample_size = 2\n",
    "lower_size = 100\n",
    "upper_size = 2100 ##2047\n",
    "step_size = 10\n",
    "\n",
    "sizes = np.arange(lower_size, upper_size + step_size, step_size)\n",
    "samples = np.arange(1, sample_size + 1, 1)\n",
    "\n",
    "input_gen_processors = 10\n",
    "\n",
    "input_dir = r'resources\\section_size_comparison\\input_matrices'\n",
    "input_file_prefix = 'SingMat'\n",
    "\n",
    "benchmark_processors = 10\n",
    "\n",
    "output_dir = r'resources\\section_size_comparison'\n",
    "output_file_prefix = 'SectionSizeComparison'\n",
    "\n",
    "output_file_fieldnames = ['size', 'run', 'sec_size', 'num_gates', 'process_time', 'initial_rss', 'final_rss']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### INPUT GENERATION\n",
    "\n",
    "Generate some matrices and save them to files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10000, '..\\\\resources\\\\section_size_comparison\\\\input_matrices\\\\SingMat_100_1.txt')\n",
      "(100, 10000, '..\\\\resources\\\\section_size_comparison\\\\input_matrices\\\\SingMat_100_2.txt')\n",
      "(110, 12100, '..\\\\resources\\\\section_size_comparison\\\\input_matrices\\\\SingMat_110_1.txt')\n",
      "(110, 12100, '..\\\\resources\\\\section_size_comparison\\\\input_matrices\\\\SingMat_110_2.txt')\n",
      "(120, 14400, '..\\\\resources\\\\section_size_comparison\\\\input_matrices\\\\SingMat_120_1.txt')\n",
      "(120, 14400, '..\\\\resources\\\\section_size_comparison\\\\input_matrices\\\\SingMat_120_2.txt')\n",
      "(130, 16900, '..\\\\resources\\\\section_size_comparison\\\\input_matrices\\\\SingMat_130_1.txt')\n",
      "(130, 16900, '..\\\\resources\\\\section_size_comparison\\\\input_matrices\\\\SingMat_130_2.txt')\n",
      "(140, 19600, '..\\\\resources\\\\section_size_comparison\\\\input_matrices\\\\SingMat_140_1.txt')\n",
      "(140, 19600, '..\\\\resources\\\\section_size_comparison\\\\input_matrices\\\\SingMat_140_2.txt')\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None, None, None]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_gen_argument_tuples = ([(size, size * size, rf'..\\{input_dir}\\{input_file_prefix}_{size}_{sample}.txt') for size in sizes for sample in samples])\n",
    "\n",
    "[print(argument_tuple) for argument_tuple in input_gen_argument_tuples[:min(10, len(input_gen_argument_tuples))]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 402 matrices in size range from 100 to 2100 ...\n",
      "Saved matrices to resources\\section_size_comparison\\input_matrices ...\n"
     ]
    }
   ],
   "source": [
    "print(f'Generating {len(input_gen_argument_tuples)} matrices in size range from {lower_size} to {upper_size} ...')\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    with Pool(processes = input_gen_processors) as pool:\n",
    "        pool.starmap(write_int_matrix_file, input_gen_argument_tuples)\n",
    "\n",
    "print(f'Saved matrices to {input_dir} ...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GET FILES TO BENCHMARK\n",
    "\n",
    "Find relevant files and sort them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingMat_100_1.txt\n",
      "SingMat_100_2.txt\n",
      "SingMat_110_1.txt\n",
      "SingMat_110_2.txt\n",
      "SingMat_120_1.txt\n",
      "SingMat_120_2.txt\n",
      "SingMat_130_1.txt\n",
      "SingMat_130_2.txt\n",
      "SingMat_140_1.txt\n",
      "SingMat_140_2.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None, None, None]"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_regex = rf'({input_file_prefix}).*\\.txt'\n",
    "size_regex = r'_\\d+_'\n",
    "sample_regex = r'_\\d+\\.'\n",
    "\n",
    "input_file_names = find_files(rf'..\\{input_dir}', file_regex)\n",
    "input_file_names.sort(key = lambda input_file_name: numbers_from_file_name(input_file_name, size_regex, sample_regex))\n",
    "\n",
    "[print(input_file_name) for input_file_name in input_file_names[:min(10, len(input_file_names))]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GET DIFFERENT SECTION SIZES\n",
    "\n",
    "Get the different section sizes and produce input tuples together with the files."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "     size  norm_sec_size  opt_sec_size\n98    100              3             3\n99    101              3             3\n100   102              3             3\n101   103              3             3\n102   104              3             3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>size</th>\n      <th>norm_sec_size</th>\n      <th>opt_sec_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>98</th>\n      <td>100</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>101</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>102</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>103</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>104</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_sizes_df = pd.read_csv(rf'..\\resources\\optimization\\SecSizes_2_5000.csv')\n",
    "section_sizes_df = section_sizes_df.loc[(section_sizes_df['size'] >= lower_size) & (section_sizes_df['size'] <= upper_size)]\n",
    "section_sizes_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "   size  sec_size_type  sec_size\n0   100  norm_sec_size         3\n1   100   opt_sec_size         3\n2   101  norm_sec_size         3\n3   101   opt_sec_size         3\n4   102  norm_sec_size         3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>size</th>\n      <th>sec_size_type</th>\n      <th>sec_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>norm_sec_size</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>opt_sec_size</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>101</td>\n      <td>norm_sec_size</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>101</td>\n      <td>opt_sec_size</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>102</td>\n      <td>norm_sec_size</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_sizes_pivot_df = section_sizes_df.set_index('size').stack().reset_index(name='sec_size').rename(columns={'level_1':'sec_size_type'})\n",
    "section_sizes_pivot_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "   size  sample               path\n0   100       1  SingMat_100_1.txt\n1   100       2  SingMat_100_2.txt\n2   110       1  SingMat_110_1.txt\n3   110       2  SingMat_110_2.txt\n4   120       1  SingMat_120_1.txt",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>size</th>\n      <th>sample</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>1</td>\n      <td>SingMat_100_1.txt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>2</td>\n      <td>SingMat_100_2.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>110</td>\n      <td>1</td>\n      <td>SingMat_110_1.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110</td>\n      <td>2</td>\n      <td>SingMat_110_2.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>120</td>\n      <td>1</td>\n      <td>SingMat_120_1.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_arguments = [(number_from_text(input_file_name, size_regex),\n",
    "                        number_from_text(input_file_name, sample_regex),\n",
    "                        input_file_name)\n",
    "                       for input_file_name in input_file_names]\n",
    "file_name_arguments_df = pd.DataFrame(file_name_arguments, columns=['size', 'sample', 'path'])\n",
    "file_name_arguments_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   size  sec_size  sample                path\n0  1849         5       1  SingMat_1849_1.txt\n1  1849         5       2  SingMat_1849_2.txt\n2  1849         5       1  SingMat_1849_1.txt\n3  1849         5       2  SingMat_1849_2.txt\n4  1871         5       1  SingMat_1871_1.txt",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>size</th>\n      <th>sec_size</th>\n      <th>sample</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1849</td>\n      <td>5</td>\n      <td>1</td>\n      <td>SingMat_1849_1.txt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1849</td>\n      <td>5</td>\n      <td>2</td>\n      <td>SingMat_1849_2.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1849</td>\n      <td>5</td>\n      <td>1</td>\n      <td>SingMat_1849_1.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1849</td>\n      <td>5</td>\n      <td>2</td>\n      <td>SingMat_1849_2.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1871</td>\n      <td>5</td>\n      <td>1</td>\n      <td>SingMat_1871_1.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#benchmark_tuples_df = pd.merge(section_sizes_pivot_df, file_name_arguments_df, on='size', how='inner')[['size', 'sec_size', 'sample', 'path']]\n",
    "#benchmark_tuples_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1849, 5, 1, 'SingMat_1849_1.txt')\n",
      "(1849, 5, 2, 'SingMat_1849_2.txt')\n",
      "(1849, 5, 1, 'SingMat_1849_1.txt')\n",
      "(1849, 5, 2, 'SingMat_1849_2.txt')\n",
      "(1871, 5, 1, 'SingMat_1871_1.txt')\n",
      "(1871, 5, 2, 'SingMat_1871_2.txt')\n",
      "(1871, 5, 1, 'SingMat_1871_1.txt')\n",
      "(1871, 5, 2, 'SingMat_1871_2.txt')\n",
      "(1893, 5, 1, 'SingMat_1893_1.txt')\n",
      "(1893, 5, 2, 'SingMat_1893_2.txt')\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None, None, None]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#benchmark_tuples_list = [tuple(benchmark_tuple) for benchmark_tuple in file_name_arguments_df.values.tolist(), for]\n",
    "\n",
    "#[print(benchmark_tuple) for benchmark_tuple in benchmark_tuples_list[:min(10, len(benchmark_tuples_list))]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 1, 'SingMat_100_1.txt')\n",
      "(100, 6, 1, 'SingMat_100_1.txt')\n",
      "(100, 5, 2, 'SingMat_100_2.txt')\n",
      "(100, 6, 2, 'SingMat_100_2.txt')\n",
      "(110, 5, 1, 'SingMat_110_1.txt')\n",
      "(110, 6, 1, 'SingMat_110_1.txt')\n",
      "(110, 5, 2, 'SingMat_110_2.txt')\n",
      "(110, 6, 2, 'SingMat_110_2.txt')\n",
      "(120, 5, 1, 'SingMat_120_1.txt')\n",
      "(120, 6, 1, 'SingMat_120_1.txt')\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None, None, None]"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_sizes_hard = [5, 6]\n",
    "\n",
    "benchmark_tuples_list = [(size, sec_size, sample, path) for size, sample, path in file_name_arguments_df.values.tolist() for sec_size in section_sizes_hard]\n",
    "\n",
    "[print(benchmark_tuple) for benchmark_tuple in benchmark_tuples_list[:min(10, len(benchmark_tuples_list))]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BENCHMARK\n",
    "\n",
    "Prepare the arguments.\n",
    "\n",
    "Read each file into a matrix, perform a benchmark and save the results in a file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "benchmark_argument_tuples = [(synthesise_circuit,\n",
    "                              size,\n",
    "                              sec_size,\n",
    "                              sample,\n",
    "                              rf'..\\{input_dir}\\{input_file_name}')\n",
    "                             for (size, sec_size, sample, input_file_name) in benchmark_tuples_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking runtime performance in size range from 100 to 2100 in 10 threads ...\n",
      "Saving results to resources\\section_size_comparison ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "output_file_timestamp = datetime.now().strftime('%d%m%y_%H%M')\n",
    "\n",
    "print(f'Benchmarking runtime performance in size range from {lower_size} to {upper_size} in {benchmark_processors} threads ...')\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    with Pool(processes = benchmark_processors) as pool:\n",
    "        result_tuples = pool.starmap(load_matrix_and_benchmark, benchmark_argument_tuples)\n",
    "\n",
    "print(f'Saving results to {output_dir} ...')\n",
    "\n",
    "with open(rf'..\\{output_dir}\\{output_file_prefix}_{output_file_timestamp}.csv', mode='w', newline='') as output_file:\n",
    "    writer = csv.DictWriter(output_file, fieldnames=output_file_fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for (size, run, sec_size, num_gates, process_time, initial_rss, final_rss) in result_tuples:\n",
    "\n",
    "        writer.writerow({'size': size, 'run': run, 'sec_size': sec_size, 'num_gates': num_gates, 'process_time': process_time, 'initial_rss': initial_rss, 'final_rss': final_rss})\n",
    "\n",
    "print('Done.')\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}