{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# COMPARE DIFFERENT IMPLEMENTATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IMPORTS\n",
    "\n",
    "Perform imports and check environment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 threads available on this machineee.\n",
      "CUDA is available on this machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np\n",
    "from src.input.write_files import write_int_matrix_file\n",
    "from src.input.read_files import find_files, numbers_from_file_name, normal_sec_size_int_from_file_name, number_from_text\n",
    "from datetime import datetime\n",
    "from src.algorithm.circuit_synthesis_vanilla import synthesise_circuit as synthesise_circuit_vanilla\n",
    "from src.algorithm.circuit_synthesis_torch import synthesise_circuit as synthesise_circuit_torch\n",
    "from src.algorithm.execution import load_matrix_and_benchmark, load_tensor_and_benchmark\n",
    "#from src.algorithm.execution import load_matrix_and_benchmark\n",
    "import csv\n",
    "\n",
    "print(f'There are {cpu_count()} threads available on this machineee.')\n",
    "print(f'CUDA is{\" \" if torch.cuda.is_available() else \" not \"}available on this machine.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### INPUT GENERATION PARAMETERS\n",
    "\n",
    "Defining the parameters for the input generation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "sample_size = 2\n",
    "lower_size = 100\n",
    "upper_size = 115\n",
    "step_size = 5\n",
    "\n",
    "sizes = np.arange(lower_size, upper_size + step_size, step_size)\n",
    "samples = np.arange(1, sample_size + 1, 1)\n",
    "\n",
    "input_gen_processors = 10\n",
    "\n",
    "input_dir = r'resources\\implementation_comparison\\input_matrices'\n",
    "input_file_prefix = 'SingMat'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### INPUT GENERATION\n",
    "\n",
    "Generate the matrices and save them to files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10000, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_100_1.txt')\n",
      "(100, 10000, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_100_2.txt')\n",
      "(105, 11025, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_105_1.txt')\n",
      "(105, 11025, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_105_2.txt')\n",
      "(110, 12100, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_110_1.txt')\n",
      "(110, 12100, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_110_2.txt')\n",
      "(115, 13225, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_115_1.txt')\n",
      "(115, 13225, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_115_2.txt')\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_gen_argument_tuples = ([(size, size * size, rf'..\\{input_dir}\\{input_file_prefix}_{size}_{sample}.txt') for size in sizes for sample in samples])\n",
    "\n",
    "[print(argument_tuple) for argument_tuple in input_gen_argument_tuples[:min(10, len(input_gen_argument_tuples))]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 8 matrices in size range from 100 to 115 ...\n",
      "Saved matrices to resources\\implementation_comparison\\input_matrices ...\n"
     ]
    }
   ],
   "source": [
    "print(f'Generating {len(input_gen_argument_tuples)} matrices in size range from {lower_size} to {upper_size} ...')\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    with Pool(processes = input_gen_processors) as pool:\n",
    "        pool.starmap(write_int_matrix_file, input_gen_argument_tuples)\n",
    "\n",
    "print(f'Saved matrices to {input_dir} ...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GET FILES TO BENCHMARK\n",
    "\n",
    "Find relevant files and sort them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingMat_100_1.txt\n",
      "SingMat_100_2.txt\n",
      "SingMat_105_1.txt\n",
      "SingMat_105_2.txt\n",
      "SingMat_110_1.txt\n",
      "SingMat_110_2.txt\n",
      "SingMat_115_1.txt\n",
      "SingMat_115_2.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_regex = rf'({input_file_prefix}).*\\.txt'\n",
    "size_regex = r'_\\d+_'\n",
    "sample_regex = r'_\\d+\\.'\n",
    "\n",
    "input_file_names = find_files(rf'..\\{input_dir}', file_regex)\n",
    "input_file_names.sort(key = lambda input_file_name: numbers_from_file_name(input_file_name, size_regex, sample_regex))\n",
    "\n",
    "[print(input_file_name) for input_file_name in input_file_names[:min(10, len(input_file_names))]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GET DIFFERENT SECTION SIZES\n",
    "\n",
    "Get the normal section sizes and produce input tuples together with the files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "     size  norm_sec_size\n98    100              3\n99    101              3\n100   102              3\n101   103              3\n102   104              3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>size</th>\n      <th>norm_sec_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>98</th>\n      <td>100</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>101</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>102</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>103</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>104</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_sizes_df = pd.read_csv(rf'..\\resources\\optimization\\SecSizes_2_5000.csv')\n",
    "section_sizes_df = section_sizes_df.loc[(section_sizes_df['size'] >= lower_size) & (section_sizes_df['size'] <= upper_size)][['size', 'norm_sec_size']]\n",
    "section_sizes_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   size  sec_size_type  sec_size\n0   100  norm_sec_size         3\n1   101  norm_sec_size         3\n2   102  norm_sec_size         3\n3   103  norm_sec_size         3\n4   104  norm_sec_size         3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>size</th>\n      <th>sec_size_type</th>\n      <th>sec_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>norm_sec_size</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>101</td>\n      <td>norm_sec_size</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>102</td>\n      <td>norm_sec_size</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>103</td>\n      <td>norm_sec_size</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>104</td>\n      <td>norm_sec_size</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_sizes_pivot_df = section_sizes_df.set_index('size').stack().reset_index(name='sec_size').rename(columns={'level_1':'sec_size_type'})\n",
    "section_sizes_pivot_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   size  sample               path\n0   100       1  SingMat_100_1.txt\n1   100       2  SingMat_100_2.txt\n2   105       1  SingMat_105_1.txt\n3   105       2  SingMat_105_2.txt\n4   110       1  SingMat_110_1.txt",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>size</th>\n      <th>sample</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>1</td>\n      <td>SingMat_100_1.txt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>2</td>\n      <td>SingMat_100_2.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>105</td>\n      <td>1</td>\n      <td>SingMat_105_1.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>105</td>\n      <td>2</td>\n      <td>SingMat_105_2.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>110</td>\n      <td>1</td>\n      <td>SingMat_110_1.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_arguments = [(number_from_text(input_file_name, size_regex),\n",
    "                        number_from_text(input_file_name, sample_regex),\n",
    "                        input_file_name)\n",
    "                       for input_file_name in input_file_names]\n",
    "file_name_arguments_df = pd.DataFrame(file_name_arguments, columns =['size', 'sample', 'path'])\n",
    "file_name_arguments_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   size  sec_size  sample               path\n0   100         3       1  SingMat_100_1.txt\n1   100         3       2  SingMat_100_2.txt\n2   105         3       1  SingMat_105_1.txt\n3   105         3       2  SingMat_105_2.txt\n4   110         3       1  SingMat_110_1.txt",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>size</th>\n      <th>sec_size</th>\n      <th>sample</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>3</td>\n      <td>1</td>\n      <td>SingMat_100_1.txt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>3</td>\n      <td>2</td>\n      <td>SingMat_100_2.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>105</td>\n      <td>3</td>\n      <td>1</td>\n      <td>SingMat_105_1.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>105</td>\n      <td>3</td>\n      <td>2</td>\n      <td>SingMat_105_2.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>110</td>\n      <td>3</td>\n      <td>1</td>\n      <td>SingMat_110_1.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_tuples_df = pd.merge(section_sizes_pivot_df, file_name_arguments_df, on='size', how='inner')[['size', 'sec_size', 'sample', 'path']]\n",
    "benchmark_tuples_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<function synthesise_circuit at 0x000002657D87A280>, 100, 3, 1, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_100_1.txt')\n",
      "(<function synthesise_circuit at 0x000002657D87A280>, 100, 3, 2, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_100_2.txt')\n",
      "(<function synthesise_circuit at 0x000002657D87A280>, 105, 3, 1, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_105_1.txt')\n",
      "(<function synthesise_circuit at 0x000002657D87A280>, 105, 3, 2, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_105_2.txt')\n",
      "(<function synthesise_circuit at 0x000002657D87A280>, 110, 3, 1, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_110_1.txt')\n",
      "(<function synthesise_circuit at 0x000002657D87A280>, 110, 3, 2, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_110_2.txt')\n",
      "(<function synthesise_circuit at 0x000002657D87A280>, 115, 3, 1, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_115_1.txt')\n",
      "(<function synthesise_circuit at 0x000002657D87A280>, 115, 3, 2, '..\\\\resources\\\\implementation_comparison\\\\input_matrices\\\\SingMat_115_2.txt')\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_tuples_list = [tuple(benchmark_tuple) for benchmark_tuple in benchmark_tuples_df.values.tolist()]\n",
    "\n",
    "benchmark_argument_tuples = [(synthesise_circuit_torch,\n",
    "                              size,\n",
    "                              sec_size,\n",
    "                              sample,\n",
    "                              rf'..\\{input_dir}\\{input_file_name}')\n",
    "                             for (size, sec_size, sample, input_file_name) in benchmark_tuples_list]\n",
    "\n",
    "[print(argument_tuple) for argument_tuple in benchmark_argument_tuples[:min(10, len(benchmark_argument_tuples))]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DEFINE BENCHMARK PARAMETERS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "output_dir = r'resources\\implementation_comparison'\n",
    "output_file_prefix = 'ImplementationComparison'\n",
    "\n",
    "output_file_fieldnames = ['size', 'run', 'sec_size', 'num_gates', 'process_time', 'initial_rss', 'final_rss']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BENCHMARK VANILLA\n",
    "\n",
    "Read each file into a matrix, perform a benchmark and save the results in a file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading matrix from ..\\resources\\implementation_comparison\\input_matrices\\SingMat_100_1.txt ...\n",
      "Benchmarking sample 1 ... matrix size: 100, section size: 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "logical_xor(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-1b88419d42f1>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mbenchmark_argument_tuple\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mbenchmark_argument_tuples\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m     \u001B[0mvanilla_result_tuples\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mload_matrix_and_benchmark\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mbenchmark_argument_tuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"Saving results to '{output_dir} ...\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Dev\\cnot_synthesis\\src\\algorithm\\execution.py\u001B[0m in \u001B[0;36mload_matrix_and_benchmark\u001B[1;34m(circuit_synthesis, size, sec_size, sample, path)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    117\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf'Benchmarking sample {sample} ... matrix size: {size}, section size: {sec_size}'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 118\u001B[1;33m     \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcircuit\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprocess_time\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minitial_rss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfinal_rss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_and_benchmark\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcircuit_synthesis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msec_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    119\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    120\u001B[0m     \u001B[0mnum_gates\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcircuit\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Dev\\cnot_synthesis\\src\\algorithm\\execution.py\u001B[0m in \u001B[0;36mcheck_and_benchmark\u001B[1;34m(circuit_synthesis, mat, sec_size)\u001B[0m\n\u001B[0;32m     67\u001B[0m     \u001B[0minitial_cpu_times\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mps\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu_times\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 69\u001B[1;33m     \u001B[0mmat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcircuit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcircuit_synthesis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msec_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     70\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m     \u001B[0mfinal_cpu_times\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mps\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu_times\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Dev\\cnot_synthesis\\src\\algorithm\\circuit_synthesis_torch.py\u001B[0m in \u001B[0;36msynthesise_circuit\u001B[1;34m(tensor, size, sec_size)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0msynthesise_circuit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msec_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlower_triangular_reverse_circuit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msynthesise_lower_triangular_circuit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msec_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mlower_triangular_circuit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlower_triangular_reverse_circuit\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Dev\\cnot_synthesis\\src\\algorithm\\circuit_synthesis_torch.py\u001B[0m in \u001B[0;36msynthesise_lower_triangular_circuit\u001B[1;34m(tensor, size, sec_size)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 48\u001B[1;33m                     \u001B[0mtensor\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mrow_idx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlogical_xor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mrow_idx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpatterns\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0msub_row_pattern\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m                     \u001B[0mreverse_circuit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpatterns\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0msub_row_pattern\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrow_idx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: logical_xor(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "vanilla_output_file_postfix = 'Vanilla'\n",
    "output_file_timestamp = datetime.now().strftime(\"%d%m%y_%H%M\")\n",
    "\n",
    "#print(f'Benchmarking runtime performance in size range from {lower_size} to {upper_size} in {benchmark_processors} threads ...')\n",
    "\n",
    "vanilla_result_tuples = []\n",
    "\n",
    "for benchmark_argument_tuple in benchmark_argument_tuples:\n",
    "\n",
    "    vanilla_result_tuples.append(load_matrix_and_benchmark(*benchmark_argument_tuple))\n",
    "\n",
    "print(f\"Saving results to '{output_dir} ...\")\n",
    "\n",
    "with open(rf'..\\{output_dir}\\{output_file_prefix}_{vanilla_output_file_postfix}_{output_file_timestamp}.csv', mode='w', newline='') as output_file:\n",
    "    writer = csv.DictWriter(output_file, fieldnames=output_file_fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for (size, run, sec_size, num_gates, process_time, initial_rss, final_rss) in vanilla_result_tuples:\n",
    "\n",
    "        writer.writerow({'size': size, 'run': run, 'sec_size': sec_size, 'num_gates': num_gates, 'process_time': process_time, 'initial_rss': initial_rss, 'final_rss': final_rss})\n",
    "\n",
    "print('Done.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BENCHMARK TORCH\n",
    "\n",
    "Read each file into a tensor, perform a benchmark and save the results in a file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PyTorch implementation will be executed on the device cuda.\n"
     ]
    }
   ],
   "source": [
    "torch_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'The PyTorch implementation will be executed on the device {torch_device}.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tensor from ..\\resources\\implementation_comparison\\input_matrices\\SingMat_100_1.txt ...\n",
      "Tensor allocated on cuda ...\n",
      "Benchmarking sample 1 ... matrix size: 100, section size: 3\n",
      "Loading tensor from ..\\resources\\implementation_comparison\\input_matrices\\SingMat_100_2.txt ...\n",
      "Tensor allocated on cuda ...\n",
      "Benchmarking sample 2 ... matrix size: 100, section size: 3\n",
      "Loading tensor from ..\\resources\\implementation_comparison\\input_matrices\\SingMat_105_1.txt ...\n",
      "Tensor allocated on cuda ...\n",
      "Benchmarking sample 1 ... matrix size: 105, section size: 3\n",
      "Loading tensor from ..\\resources\\implementation_comparison\\input_matrices\\SingMat_105_2.txt ...\n",
      "Tensor allocated on cuda ...\n",
      "Benchmarking sample 2 ... matrix size: 105, section size: 3\n",
      "Loading tensor from ..\\resources\\implementation_comparison\\input_matrices\\SingMat_110_1.txt ...\n",
      "Tensor allocated on cuda ...\n",
      "Benchmarking sample 1 ... matrix size: 110, section size: 3\n",
      "Loading tensor from ..\\resources\\implementation_comparison\\input_matrices\\SingMat_110_2.txt ...\n",
      "Tensor allocated on cuda ...\n",
      "Benchmarking sample 2 ... matrix size: 110, section size: 3\n",
      "Loading tensor from ..\\resources\\implementation_comparison\\input_matrices\\SingMat_115_1.txt ...\n",
      "Tensor allocated on cuda ...\n",
      "Benchmarking sample 1 ... matrix size: 115, section size: 3\n",
      "Loading tensor from ..\\resources\\implementation_comparison\\input_matrices\\SingMat_115_2.txt ...\n",
      "Tensor allocated on cuda ...\n",
      "Benchmarking sample 2 ... matrix size: 115, section size: 3\n",
      "Saving results to 'resources\\implementation_comparison ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "torch_output_file_postfix = 'Torch'\n",
    "output_file_timestamp = datetime.now().strftime(\"%d%m%y_%H%M\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f'Benchmarking runtime performance in size range from {lower_size} to {upper_size} in {benchmark_processors} threads ...')\n",
    "\n",
    "torch_result_tuples = []\n",
    "\n",
    "for benchmark_argument_tuple in benchmark_argument_tuples:\n",
    "\n",
    "    torch_result_tuples.append(load_tensor_and_benchmark(*benchmark_argument_tuple, torch_device))\n",
    "\n",
    "print(f\"Saving results to '{output_dir} ...\")\n",
    "\n",
    "with open(rf'..\\{output_dir}\\{output_file_prefix}_{torch_output_file_postfix}_{output_file_timestamp}.csv', mode='w', newline='') as output_file:\n",
    "    writer = csv.DictWriter(output_file, fieldnames=output_file_fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for (size, run, sec_size, num_gates, process_time, initial_rss, final_rss) in torch_result_tuples:\n",
    "\n",
    "        writer.writerow({'size': size, 'run': run, 'sec_size': sec_size, 'num_gates': num_gates, 'process_time': process_time, 'initial_rss': initial_rss, 'final_rss': final_rss})\n",
    "\n",
    "print('Done.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}